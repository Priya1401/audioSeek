# Airflow base (2.9.2)
FROM apache/airflow:2.9.2

# ---- Root section: system libs + cache dirs/symlinks ----
USER root

# Audio/ML runtime deps
RUN apt-get update && apt-get install -y --no-install-recommends \
    libgomp1 \
    libsndfile1 \
    ffmpeg \
 && rm -rf /var/lib/apt/lists/*

# Cache locations (make everything live under /opt/airflow)
ENV HF_HOME=/opt/airflow/.cache/huggingface \
    HF_HUB_CACHE=/opt/airflow/.cache/huggingface \
    HUGGINGFACE_HUB_CACHE=/opt/airflow/.cache/huggingface \
    TRANSFORMERS_CACHE=/opt/airflow/.cache/huggingface \
    XDG_CACHE_HOME=/opt/airflow/.cache \
    TORCH_HOME=/opt/airflow/.cache/torch \
    HOME=/opt/airflow \
    PYTHONPATH=/opt/airflow

# Create caches + a symlink for libs that still write to ~/.cache/huggingface
RUN set -eux; \
    mkdir -p /opt/airflow/.cache/huggingface /opt/airflow/.cache/torch; \
    mkdir -p /home/airflow/.cache; \
    ln -sfn /opt/airflow/.cache/huggingface /home/airflow/.cache/huggingface; \
    chown -R ${AIRFLOW_UID:-50000}:0 /opt/airflow/.cache /home/airflow/.cache

# ---- Switch to airflow user for Python deps + model prefetch ----
USER airflow
WORKDIR /opt/airflow

# Python deps
COPY requirements.txt /requirements.txt
RUN pip install --no-cache-dir -r /requirements.txt

# Prefetch Faster-Whisper model into the cache to avoid runtime downloads
# You can change FW_MODEL to small/medium/large-v3 if needed.
ARG FW_MODEL=base
ARG FW_COMPUTE=int8   # CPU-friendly; on GPU you'd use float16
RUN python - <<'PY'
import os
from faster_whisper import WhisperModel

model_name = os.environ.get("FW_MODEL", "base")
compute = os.environ.get("FW_COMPUTE", "int8")
cache_dir = os.environ.get("HF_HOME", "/opt/airflow/.cache/huggingface")

print(f"[MODEL PREFETCH] Downloading Faster-Whisper '{model_name}' to {cache_dir} ...")
# device="cpu" for deterministic prefetch; runtime can still choose CUDA later
WhisperModel(model_name, device="cpu", compute_type=compute, download_root=cache_dir)
print("[MODEL PREFETCH] Done.")
PY

# If you want to force offline at runtime (only after cache is definitely present), uncomment:
# ENV HF_HUB_OFFLINE=1

# Done. Your dags/scripts/data will be volume-mounted by docker-compose.
