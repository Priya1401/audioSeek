name: AudioSeek CI Pipeline

on:
  push:
    branches: ["main", "refactor", "dev"]
  pull_request:
    branches: ["main", "refactor", "dev"]
  workflow_dispatch:

jobs:
  # ------------------------------------------------------
  # 1) Unit / Integration Tests
  # ------------------------------------------------------
  run-tests:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python 3.10
      uses: actions/setup-python@v5
      with:
        python-version: "3.10"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r Data-Pipeline/requirements-airflow.txt

    - name: Run test suite
      working-directory: Data-Pipeline
      run: |
        pytest scripts/tests/test_transcription.py
        pytest scripts/tests/test_transcription_tasks.py
        pytest scripts/tests/test_summary.py

  # --------------------------------------------------
  # 2) MLFLOW SMOKE TEST (ENDPOINTS)
  # --------------------------------------------------
#  mlflow-smoke:
#    runs-on: ubuntu-latest
##    needs: run-tests
#
#    env:
#      # Smoke-test book configuration (used by mlflow_smoke_test.py)
#
#      MLFLOW_TRACKING_URI: "file:./mlruns_ci"
#      TEXTPROC_BASE_URL: "http://localhost:8001"
#      SMOKE_BOOK_ID: "ci-test-book"
#      SMOKE_BOOK_FOLDER: "data/ci_smoke_book"
#
#      # These must be set in GitHub repo Secrets if your endpoints require them
#      GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
#      GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
#      GCP_REGION: "us-central1"
#      GCP_INDEX_ID: "audioseek-embeddings"
#      GCP_INDEX_ENDPOINT_ID: ""
#      GCP_CREDENTIALS_PATH: "/app/gcp-credentials.json"
#
#    steps:
#      - name: Checkout repository
#        uses: actions/checkout@v4
#
#      - name: Set up Python 3.10
#        uses: actions/setup-python@v5
#        with:
#          python-version: "3.10"
#
#      - name: Install smoke test dependencies
#        run: |
#          python -m pip install --upgrade pip
#          pip install mlflow requests
#
#      - name: Start services with Docker Compose
#        working-directory: Data-Pipeline
#        run: |
#          docker compose up -d transcription-textprocessing mlflow
#
#      - name: Wait for /health to be ready (quick check)
#        working-directory: Data-Pipeline
#        run: |
#          for i in {1..30}; do
#            if curl -fsS http://localhost:8001/health > /dev/null; then
#              echo "Service is up"
#              exit 0
#            fi
#            echo "Waiting for text-processing service..."
#            sleep 5
#          done
#          echo "Service did not become healthy in time"
#          docker compose logs transcription-textprocessing || true
#          exit 1
#
#      - name: Run MLflow smoke test (health + process-full + qa/ask)
#        working-directory: Data-Pipeline/services/text_processing
#        run: python mlflow_smoke_test.py
#
#      - name: Dump Docker logs on failure
#        if: failure()
#        working-directory: Data-Pipeline
#        run: |
#          docker compose logs transcription-textprocessing mlflow || true